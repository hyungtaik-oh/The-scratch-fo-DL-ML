{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc617db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "device = torch.device('cuda:0')\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637d5903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pds.read_csv('data/ratings.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615ddb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['uid2idx'] = LabelEncoder().fit_transform(df['userId'].values)\n",
    "df['iid2idx'] = LabelEncoder().fit_transform(df['movieId'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0de517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>uid2idx</th>\n",
       "      <th>iid2idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "      <td>609</td>\n",
       "      <td>9416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "      <td>609</td>\n",
       "      <td>9443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "      <td>609</td>\n",
       "      <td>9444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "      <td>609</td>\n",
       "      <td>9445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "      <td>609</td>\n",
       "      <td>9485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp  uid2idx  iid2idx\n",
       "0            1        1     4.0   964982703        0        0\n",
       "1            1        3     4.0   964981247        0        2\n",
       "2            1        6     4.0   964982224        0        5\n",
       "3            1       47     5.0   964983815        0       43\n",
       "4            1       50     5.0   964982931        0       46\n",
       "...        ...      ...     ...         ...      ...      ...\n",
       "100831     610   166534     4.0  1493848402      609     9416\n",
       "100832     610   168248     5.0  1493850091      609     9443\n",
       "100833     610   168250     5.0  1494273047      609     9444\n",
       "100834     610   168252     5.0  1493846352      609     9445\n",
       "100835     610   170875     3.0  1493846415      609     9485\n",
       "\n",
       "[100836 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8a6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = df['uid2idx'].unique().shape[0]\n",
    "num_items = df['iid2idx'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33f72cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of users : 610\n",
      "# of contents (movie) : 9724\n",
      "sparsity of matrix: 0.9830003169443864\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1 - len(df) / (num_users * num_items) # 데이터에서 rating이 빈 것의 비율(행렬 만들었을 때)\n",
    "\n",
    "print(f'# of users : {num_users}') \n",
    "print(f'# of contents (movie) : {num_items}')\n",
    "print(f'sparsity of matrix: {sparsity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6630ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data, \n",
    "        train = False, \n",
    "        test_ratio = 0.3,\n",
    "        random_state = 123\n",
    "    ):\n",
    "        \n",
    "        self.train_data, self.test_data = train_test_split(\n",
    "            data, \n",
    "            test_size=test_ratio, \n",
    "            random_state=random_state,\n",
    "            stratify=data.userId\n",
    "        )\n",
    "        \n",
    "        if train:\n",
    "            self.data = self.train_data\n",
    "        else:\n",
    "            self.data = self.test_data\n",
    "              \n",
    "        self.users = torch.tensor(self.data['uid2idx'].values) \n",
    "        self.items = torch.tensor(self.data['iid2idx'].values)\n",
    "        self.ratings = torch.tensor(self.data['rating'].values) \n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        users = self.users[idx]\n",
    "        items = self.items[idx]\n",
    "        ratings = self.ratings[idx]\n",
    "        return users, items, ratings.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a578c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_DL = DataLoader(CustomDataset(df, True), 64, True)\n",
    "Test_DL = DataLoader(CustomDataset(df, False), 64, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55acfcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Embedding as embedding\n",
    "\n",
    "class MF(Module):\n",
    "    '''\n",
    "    Matrix Factorization\n",
    "    '''\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_factors, \n",
    "        num_users, \n",
    "        num_items, \n",
    "        mu\n",
    "    ):\n",
    "        super(MF,self).__init__()\n",
    "        \n",
    "        self.P = embedding(num_users, num_factors)\n",
    "        self.Q = embedding(num_items, num_factors)\n",
    "        \n",
    "        self.user_bias = embedding(num_users,  1)\n",
    "        self.item_bias = embedding(num_items,  1)\n",
    "        \n",
    "        self.mu = mu\n",
    "        \n",
    "    def forward(self, user_id, item_id):\n",
    "        P_u = self.P(user_id)\n",
    "        Q_i = self.Q(item_id)\n",
    "        b_u = self.user_bias(user_id)\n",
    "        b_i = self.item_bias(item_id)\n",
    "\n",
    "        outputs = torch.sum((P_u*Q_i), axis=1) + \\\n",
    "                  torch.squeeze(b_u) +\\\n",
    "                  torch.squeeze(b_i) +\\\n",
    "                  self.mu\n",
    "                  \n",
    "        \n",
    "        return outputs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa8c2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class torch_trainer:\n",
    "    def __init__(self, model, data, batch_size, loss_fn):\n",
    "        self.model = model\n",
    "        self.dataloader = DataLoader(data, batch_size, True)\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = .001)\n",
    "        \n",
    "        \n",
    "    def __training_batch_step__(self, batch):\n",
    "        u, i, r = batch # u:user, i:item, r:rating\n",
    "        \n",
    "        users = u.to(device)\n",
    "        items = i.to(device)\n",
    "        ratings = r.to(device)\n",
    "\n",
    "        preds = self.model(users, items)\n",
    "        \n",
    "        L2_reg=0\n",
    "        for params in self.model.parameters():\n",
    "            L2_reg += params.norm(2)\n",
    "        \n",
    "        losses = self.loss_fn(preds, ratings) + L2_reg\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return losses.item()\n",
    "\n",
    "    \n",
    "    def __training_epoch__(self, epoch_numb):\n",
    "        loss_lists = []\n",
    "        TQ = tqdm(self.dataloader)\n",
    "        for n, batch in enumerate(TQ,1):\n",
    "            loss_lists.append(self.__training_batch_step__(batch))\n",
    "            TQ.set_description_str(f'Epoch : {epoch_numb}')\n",
    "            TQ.set_postfix_str(f'Loss : {sum(loss_lists) / n:.4}')\n",
    "        return sum(loss_lists) / n\n",
    "    \n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    \n",
    "    def fit(self, loop_numb):\n",
    "        self.model.train()\n",
    "        history = dict(\n",
    "            loss = []\n",
    "        )\n",
    "        for n in range(loop_numb):\n",
    "            history['loss'].append(\n",
    "                self.__training_epoch__(n)\n",
    "            )\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d5d73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch_trainer(\n",
    "    model = MF(\n",
    "        num_factors=6,\n",
    "        num_users=num_users,\n",
    "        num_items=num_items,\n",
    "        mu=torch.tensor(df['rating'].mean())\n",
    "    ).to(device),\n",
    "    data = CustomDataset(df, True),\n",
    "    batch_size = 64,\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8709bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abca0da151f74161957d745bf0145c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078bd43e0d744d3f8e944d08f0f4d12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1166846c0e8c48dc87a0bf926f2e4300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c462dbdc6004893b230dd5cae683685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec9bdba51a9492997a53acb3922aba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf53f815cd60414aa8c4ca862d89923f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f875a49229949c8bd30a51577f1c99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e76efd27a74b129214caf978cb89cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494475c81cf242e79cf80a2a117bf098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cd6d4f41bd4bcb892068ab9f50a946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1103.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn [10], line 52\u001b[0m, in \u001b[0;36mtorch_trainer.fit\u001b[0;34m(self, loop_numb)\u001b[0m\n\u001b[1;32m     47\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     48\u001b[0m     loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(loop_numb):\n\u001b[1;32m     51\u001b[0m     history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 52\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__training_epoch__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "Cell \u001b[0;32mIn [10], line 35\u001b[0m, in \u001b[0;36mtorch_trainer.__training_epoch__\u001b[0;34m(self, epoch_numb)\u001b[0m\n\u001b[1;32m     33\u001b[0m TQ \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(TQ,\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 35\u001b[0m     loss_lists\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__training_batch_step__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m     TQ\u001b[38;5;241m.\u001b[39mset_description_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_numb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m     TQ\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(loss_lists) \u001b[38;5;241m/\u001b[39m n\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [10], line 25\u001b[0m, in \u001b[0;36mtorch_trainer.__training_batch_step__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     22\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(preds, ratings) \u001b[38;5;241m+\u001b[39m L2_reg\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = trainer.fit(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77223598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader): \n",
    "    model.eval()\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    infos = dict()\n",
    "    loss_sum=0\n",
    "    \n",
    "    with torch.no_grad():   \n",
    "        \n",
    "        for idx, (u,i,r) in enumerate(loader):\n",
    "            users = u.to(device)\n",
    "            items = i.to(device)\n",
    "            ratings = r.to(device)\n",
    "            \n",
    "            preds = model(users, items)\n",
    "            \n",
    "            losses = loss_fn(preds, ratings)\n",
    "            loss_sum += losses.item()\n",
    "\n",
    "    infos['loss'] = (loss_sum / len(loader))\n",
    "    \n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c964515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 1.0752955410495622}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    model=trainer.get_model(),\n",
    "    loader=DataLoader(CustomDataset(df, False), 64, True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73d55e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CustomDataset(df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22694fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_hat=trainer.get_model()(test.users.to(device), test.items.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "856af3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([335, 446, 402,  ..., 476, 598, 372])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "066bfd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,  364, 2155,  ...,  914, 1054,  153])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af1fd70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5015, 3.5015, 3.5015,  ..., 3.5018, 3.5011, 3.5016], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e08f6e08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>uid2idx</th>\n",
       "      <th>iid2idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51837</th>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122227329</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51838</th>\n",
       "      <td>336</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122227549</td>\n",
       "      <td>335</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51839</th>\n",
       "      <td>336</td>\n",
       "      <td>47</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1122227343</td>\n",
       "      <td>335</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51840</th>\n",
       "      <td>336</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1120568496</td>\n",
       "      <td>335</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51841</th>\n",
       "      <td>336</td>\n",
       "      <td>70</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1120568169</td>\n",
       "      <td>335</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51842</th>\n",
       "      <td>336</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122227307</td>\n",
       "      <td>335</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51843</th>\n",
       "      <td>336</td>\n",
       "      <td>150</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122227547</td>\n",
       "      <td>335</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51844</th>\n",
       "      <td>336</td>\n",
       "      <td>163</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1120567987</td>\n",
       "      <td>335</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51845</th>\n",
       "      <td>336</td>\n",
       "      <td>168</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1120568038</td>\n",
       "      <td>335</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51846</th>\n",
       "      <td>336</td>\n",
       "      <td>186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1120568049</td>\n",
       "      <td>335</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51847</th>\n",
       "      <td>336</td>\n",
       "      <td>293</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227437</td>\n",
       "      <td>335</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51848</th>\n",
       "      <td>336</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227568</td>\n",
       "      <td>335</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51849</th>\n",
       "      <td>336</td>\n",
       "      <td>318</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1120568521</td>\n",
       "      <td>335</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51850</th>\n",
       "      <td>336</td>\n",
       "      <td>356</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1122227399</td>\n",
       "      <td>335</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51851</th>\n",
       "      <td>336</td>\n",
       "      <td>509</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1126182658</td>\n",
       "      <td>335</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51852</th>\n",
       "      <td>336</td>\n",
       "      <td>527</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1120568509</td>\n",
       "      <td>335</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51853</th>\n",
       "      <td>336</td>\n",
       "      <td>552</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1120568085</td>\n",
       "      <td>335</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51854</th>\n",
       "      <td>336</td>\n",
       "      <td>589</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227440</td>\n",
       "      <td>335</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51855</th>\n",
       "      <td>336</td>\n",
       "      <td>593</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227331</td>\n",
       "      <td>335</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51856</th>\n",
       "      <td>336</td>\n",
       "      <td>628</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1122227333</td>\n",
       "      <td>335</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51857</th>\n",
       "      <td>336</td>\n",
       "      <td>858</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1120568513</td>\n",
       "      <td>335</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51858</th>\n",
       "      <td>336</td>\n",
       "      <td>1246</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1139046758</td>\n",
       "      <td>335</td>\n",
       "      <td>944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51859</th>\n",
       "      <td>336</td>\n",
       "      <td>1267</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1121639122</td>\n",
       "      <td>335</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51860</th>\n",
       "      <td>336</td>\n",
       "      <td>1380</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1120567995</td>\n",
       "      <td>335</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51861</th>\n",
       "      <td>336</td>\n",
       "      <td>1625</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1120568104</td>\n",
       "      <td>335</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51862</th>\n",
       "      <td>336</td>\n",
       "      <td>1704</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122227323</td>\n",
       "      <td>335</td>\n",
       "      <td>1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51863</th>\n",
       "      <td>336</td>\n",
       "      <td>1722</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1120568202</td>\n",
       "      <td>335</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51864</th>\n",
       "      <td>336</td>\n",
       "      <td>1784</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227597</td>\n",
       "      <td>335</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51865</th>\n",
       "      <td>336</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1120568116</td>\n",
       "      <td>335</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51866</th>\n",
       "      <td>336</td>\n",
       "      <td>2028</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122227314</td>\n",
       "      <td>335</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51867</th>\n",
       "      <td>336</td>\n",
       "      <td>2268</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122227316</td>\n",
       "      <td>335</td>\n",
       "      <td>1686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51868</th>\n",
       "      <td>336</td>\n",
       "      <td>2324</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227453</td>\n",
       "      <td>335</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51869</th>\n",
       "      <td>336</td>\n",
       "      <td>2329</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1122227326</td>\n",
       "      <td>335</td>\n",
       "      <td>1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51870</th>\n",
       "      <td>336</td>\n",
       "      <td>2353</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1120568096</td>\n",
       "      <td>335</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51871</th>\n",
       "      <td>336</td>\n",
       "      <td>2360</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227242</td>\n",
       "      <td>335</td>\n",
       "      <td>1761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51872</th>\n",
       "      <td>336</td>\n",
       "      <td>2502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227584</td>\n",
       "      <td>335</td>\n",
       "      <td>1882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51873</th>\n",
       "      <td>336</td>\n",
       "      <td>2571</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227310</td>\n",
       "      <td>335</td>\n",
       "      <td>1938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51874</th>\n",
       "      <td>336</td>\n",
       "      <td>2699</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1120568026</td>\n",
       "      <td>335</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51875</th>\n",
       "      <td>336</td>\n",
       "      <td>2762</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1122227252</td>\n",
       "      <td>335</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51876</th>\n",
       "      <td>336</td>\n",
       "      <td>2858</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1122227606</td>\n",
       "      <td>335</td>\n",
       "      <td>2144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51877</th>\n",
       "      <td>336</td>\n",
       "      <td>2959</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1122227531</td>\n",
       "      <td>335</td>\n",
       "      <td>2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51878</th>\n",
       "      <td>336</td>\n",
       "      <td>3114</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1122227347</td>\n",
       "      <td>335</td>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51879</th>\n",
       "      <td>336</td>\n",
       "      <td>3147</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1122227255</td>\n",
       "      <td>335</td>\n",
       "      <td>2370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51880</th>\n",
       "      <td>336</td>\n",
       "      <td>3174</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1126221530</td>\n",
       "      <td>335</td>\n",
       "      <td>2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51881</th>\n",
       "      <td>336</td>\n",
       "      <td>3623</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1120568128</td>\n",
       "      <td>335</td>\n",
       "      <td>2696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51882</th>\n",
       "      <td>336</td>\n",
       "      <td>3948</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1120568193</td>\n",
       "      <td>335</td>\n",
       "      <td>2940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51883</th>\n",
       "      <td>336</td>\n",
       "      <td>4886</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1120568141</td>\n",
       "      <td>335</td>\n",
       "      <td>3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51884</th>\n",
       "      <td>336</td>\n",
       "      <td>4973</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1120568518</td>\n",
       "      <td>335</td>\n",
       "      <td>3617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51885</th>\n",
       "      <td>336</td>\n",
       "      <td>5445</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1120568123</td>\n",
       "      <td>335</td>\n",
       "      <td>3868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>336</td>\n",
       "      <td>7153</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1120568492</td>\n",
       "      <td>335</td>\n",
       "      <td>4791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51887</th>\n",
       "      <td>336</td>\n",
       "      <td>32587</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1139046729</td>\n",
       "      <td>335</td>\n",
       "      <td>5834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51888</th>\n",
       "      <td>336</td>\n",
       "      <td>33660</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1139046157</td>\n",
       "      <td>335</td>\n",
       "      <td>5891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51889</th>\n",
       "      <td>336</td>\n",
       "      <td>34162</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1139046805</td>\n",
       "      <td>335</td>\n",
       "      <td>5922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51890</th>\n",
       "      <td>336</td>\n",
       "      <td>36529</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1139046225</td>\n",
       "      <td>335</td>\n",
       "      <td>5968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51891</th>\n",
       "      <td>336</td>\n",
       "      <td>37729</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1139047287</td>\n",
       "      <td>335</td>\n",
       "      <td>5988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51892</th>\n",
       "      <td>336</td>\n",
       "      <td>38798</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1139047258</td>\n",
       "      <td>335</td>\n",
       "      <td>6008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp  uid2idx  iid2idx\n",
       "51837     336        1     4.0  1122227329      335        0\n",
       "51838     336        6     4.0  1122227549      335        5\n",
       "51839     336       47     4.5  1122227343      335       43\n",
       "51840     336       50     5.0  1120568496      335       46\n",
       "51841     336       70     4.0  1120568169      335       62\n",
       "51842     336      110     4.0  1122227307      335       97\n",
       "51843     336      150     4.0  1122227547      335      123\n",
       "51844     336      163     5.0  1120567987      335      136\n",
       "51845     336      168     4.0  1120568038      335      140\n",
       "51846     336      186     4.0  1120568049      335      157\n",
       "51847     336      293     5.0  1122227437      335      254\n",
       "51848     336      296     5.0  1122227568      335      257\n",
       "51849     336      318     5.0  1120568521      335      277\n",
       "51850     336      356     4.5  1122227399      335      314\n",
       "51851     336      509     5.0  1126182658      335      444\n",
       "51852     336      527     4.0  1120568509      335      461\n",
       "51853     336      552     3.0  1120568085      335      484\n",
       "51854     336      589     5.0  1122227440      335      507\n",
       "51855     336      593     5.0  1122227331      335      510\n",
       "51856     336      628     4.5  1122227333      335      533\n",
       "51857     336      858     4.0  1120568513      335      659\n",
       "51858     336     1246     4.5  1139046758      335      944\n",
       "51859     336     1267     3.5  1121639122      335      965\n",
       "51860     336     1380     2.5  1120567995      335     1062\n",
       "51861     336     1625     3.5  1120568104      335     1223\n",
       "51862     336     1704     4.0  1122227323      335     1283\n",
       "51863     336     1722     4.5  1120568202      335     1291\n",
       "51864     336     1784     5.0  1122227597      335     1321\n",
       "51865     336     2001     3.5  1120568116      335     1475\n",
       "51866     336     2028     4.0  1122227314      335     1502\n",
       "51867     336     2268     4.0  1122227316      335     1686\n",
       "51868     336     2324     5.0  1122227453      335     1729\n",
       "51869     336     2329     4.5  1122227326      335     1733\n",
       "51870     336     2353     3.5  1120568096      335     1754\n",
       "51871     336     2360     5.0  1122227242      335     1761\n",
       "51872     336     2502     5.0  1122227584      335     1882\n",
       "51873     336     2571     5.0  1122227310      335     1938\n",
       "51874     336     2699     3.5  1120568026      335     2026\n",
       "51875     336     2762     4.5  1122227252      335     2077\n",
       "51876     336     2858     5.0  1122227606      335     2144\n",
       "51877     336     2959     4.5  1122227531      335     2224\n",
       "51878     336     3114     4.0  1122227347      335     2353\n",
       "51879     336     3147     4.5  1122227255      335     2370\n",
       "51880     336     3174     5.0  1126221530      335     2390\n",
       "51881     336     3623     4.5  1120568128      335     2696\n",
       "51882     336     3948     5.0  1120568193      335     2940\n",
       "51883     336     4886     5.0  1120568141      335     3563\n",
       "51884     336     4973     5.0  1120568518      335     3617\n",
       "51885     336     5445     5.0  1120568123      335     3868\n",
       "51886     336     7153     4.5  1120568492      335     4791\n",
       "51887     336    32587     4.0  1139046729      335     5834\n",
       "51888     336    33660     4.5  1139046157      335     5891\n",
       "51889     336    34162     4.0  1139046805      335     5922\n",
       "51890     336    36529     4.0  1139046225      335     5968\n",
       "51891     336    37729     2.5  1139047287      335     5988\n",
       "51892     336    38798     3.5  1139047258      335     6008"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[np.where(df['uid2idx']==335)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a406a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
